{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chains\n",
    "链是LangChain的核心构建模块，通常将大型语言模型（LLM）和提示（Prompt）结合在一起。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLMChain\n",
    "最简单的Chain类型，直接使用即可"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "\n",
    "from langchain import PromptTemplate, OpenAI\n",
    "\n",
    "template = \"\"\"\\\n",
    "你是一个新公司的命名咨询顾问.\n",
    "为制作 {product} 的公司起好的名字? 使用中文回答问题,不少于5个名字\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "# prompt.format(product=\"五颜六色的袜子\")\n",
    "llm = OpenAI(temperature=0.9)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3m你是一个新公司的命名咨询顾问.\n",
      "为制作 五颜六色的袜子 的公司起好的名字? 使用中文回答问题,不少于5个名字\n",
      "\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "1. 色彩逸品 \n",
      "2. 五色薰心 \n",
      "3. 缤纷飨宴 \n",
      "4. 鸿运袜家 \n",
      "5. 足下时尚\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "# Chain可以把llm和Prompt组合在一起\n",
    "chain = LLMChain(llm=llm, prompt=prompt,verbose=True)\n",
    "print(chain.run(\"五颜六色的袜子\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SimpleSequentialChain\n",
    "每个步骤都有一个单一的输入/输出，一个步骤的输出是下一个步骤的输入。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.9)\n",
    "# 第一个Prompt和Chain\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "    \"你是一个新公司的命名咨询顾问.为制作 {product} 的公司起一个好的名字? 使用中文回答问题\"\n",
    ")\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt)\n",
    "\n",
    "# 第二个Prompt和Chain\n",
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"为下面的公司写一个20字的简短描述：{company_name}\"\n",
    ")\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new SimpleSequentialChain chain...\u001B[0m\n",
      "\u001B[36;1m\u001B[1;3m彩虹丝袜公司\u001B[0m\n",
      "\u001B[33;1m\u001B[1;3m彩虹丝袜公司：提供丰富多彩的时尚丝袜，让你的腿部焕发绚丽色彩。\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'彩虹丝袜公司：提供丰富多彩的时尚丝袜，让你的腿部焕发绚丽色彩。'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 把第一个Chain和第二个Chain合在一起\n",
    "overall_simple_chain = SimpleSequentialChain(chains=[chain_one, chain_two],\n",
    "                                             verbose=True\n",
    "                                            )\n",
    "overall_simple_chain.run(\"五颜六色的袜子\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential Chains\n",
    "不是所有的链都是有固定的输入和输出，有时候中间的链需要多个输入，最终也有多个输出，这个时候考虑用SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new SequentialChain chain...\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'title': '海滩上的日落悲剧',\n",
       " 'era': '维多利亚时代的英格兰',\n",
       " 'synopsis': ' “海滩上的日落悲剧”是一部充满爱情、矛盾和复仇的维多利亚时代的英格兰悲剧。它讲述了一位女士，她的丈夫意外地死去，并留下了一笔遗产给她。她决定将遗产捐给一个有悲剧背景的家庭。然而，这桩善行引起了一位男士的愤怒，他决定为此复仇，最终导致了一个悲惨的结局。',\n",
       " 'review': '\\n\\n《海滩上的日落悲剧》是一部充满爱情、矛盾和复仇的维多利亚时代英格兰悲剧。它讲述了一位女士，她的丈夫突然去世，留给她一笔遗产。她决定将这笔遗产捐给一个具有悲剧背景的家庭，而这一善行却引起了一位男士的愤怒，他决定复仇，最终导致一个悲惨的结局。\\n\\n这部剧'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 这是一个LLMChain，给定一个剧本的标题和它所处的时代，它的任务是写一个概要。\n",
    "llm = OpenAI(temperature=.7)\n",
    "template = \"\"\"你是一位剧作家。给定剧本的标题和它所处的时代，你的任务是为该标题写一个概要。\n",
    "\n",
    "标题: {title}\n",
    "时代: {era}\n",
    "剧作家: 这是上述剧本的概要:\"\"\"\n",
    "prompt_template = PromptTemplate(input_variables=[\"title\", \"era\"], template=template)\n",
    "synopsis_chain = LLMChain(llm=llm, prompt=prompt_template, output_key=\"synopsis\")\n",
    "\n",
    "# 这是一个LLMChain，给定一个剧本的概要，它的任务是写一个剧本的评论。\n",
    "llm = OpenAI(temperature=.7)\n",
    "template = \"\"\"你是一位专业的剧本评论家。给定剧本的概要，你的任务是为该剧本写一篇评论。\n",
    "\n",
    "剧本概要:\n",
    "{synopsis}\n",
    "你对上述剧本的评论:\"\"\"\n",
    "prompt_template = PromptTemplate(input_variables=[\"synopsis\"], template=template)\n",
    "review_chain = LLMChain(llm=llm, prompt=prompt_template, output_key=\"review\")\n",
    "\n",
    "\n",
    "# 这是整体链，我们按顺序运行这两个链。\n",
    "from langchain.chains import SequentialChain\n",
    "overall_chain = SequentialChain(\n",
    "    chains=[synopsis_chain, review_chain],\n",
    "    input_variables=[\"era\", \"title\"],\n",
    "    # 这里我们返回多个变量\n",
    "    output_variables=[\"synopsis\", \"review\"],\n",
    "    verbose=True)\n",
    "\n",
    "overall_chain({\"title\":\"海滩上的日落悲剧\", \"era\": \"维多利亚时代的英格兰\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RouterChains\n",
    "有时候单个串行的Chain不能满足我们的诉求，这个时候考虑使用RouterChain\n",
    "它在一系列的链（Chain）中动态地选择下一个要执行的链。这种模式通常用于处理复杂的逻辑流程，其中下一个执行的步骤取决于当前的输入或状态。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#例如，如果你正在构建一个问题回答系统，你可能有多个链，每个链专门处理一种类型的问题\n",
    "# （例如，一个处理物理问题，一个处理数学问题等）。\n",
    "# 然后，你可以使用一个\"RouterChain\"来检查每个问题的特性，并将问题路由到最适合处理该问题的链。\n",
    "from langchain.chains.router import MultiPromptChain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "physics_template = \"\"\"你是一位非常聪明的物理教授。 \\\n",
    "你擅长以简洁易懂的方式回答物理问题。 \\\n",
    "当你不知道问题的答案时，你会承认你不知道。\n",
    "\n",
    "这是一个问题：\n",
    "{input}\"\"\"\n",
    "\n",
    "math_template = \"\"\"你是一位非常好的数学家。你擅长回答数学问题。 \\\n",
    "你之所以这么好，是因为你能够将难题分解成各个组成部分， \\\n",
    "回答组成部分，然后将它们组合起来回答更广泛的问题。\n",
    "\n",
    "这是一个问题：\n",
    "{input}\"\"\"\n",
    "\n",
    "prompt_infos = [\n",
    "    {  \"name\": \"物理\", \"description\": \"适合回答物理问题\",\"prompt_template\": physics_template,},\n",
    "    {  \"name\": \"数学\", \"description\": \"适合回答数学问题\",\"prompt_template\": math_template,},\n",
    "]\n",
    "\n",
    "llm = OpenAI()\n",
    "\n",
    "destination_chains = {}\n",
    "for p_info in prompt_infos:\n",
    "    name = p_info[\"name\"]\n",
    "    prompt_template = p_info[\"prompt_template\"]\n",
    "    prompt = PromptTemplate(template=prompt_template, input_variables=[\"input\"])\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    destination_chains[name] = chain\n",
    "\n",
    "# 默认的Chain\n",
    "default_chain = ConversationChain(llm=llm, output_key=\"text\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['物理', '数学'])\n",
      "['物理: 适合回答物理问题', '数学: 适合回答数学问题']\n"
     ]
    }
   ],
   "source": [
    "# import pprint\n",
    "# pprint.pprint(destination_chains)\n",
    "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos]\n",
    "print(destination_chains.keys())\n",
    "print(destinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.router.llm_router import LLMRouterChain, RouterOutputParser\n",
    "# 物理: 适合回答物理问题', '数学: 适合回答数学问题\n",
    "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos]\n",
    "destinations_str = \"\\n\".join(destinations)\n",
    "\n",
    "router_prompt_template = \"\"\"\\\n",
    "给定一个原始的文本输入到语言模型中，选择最适合输入的模型提示。\n",
    "你将得到可用提示的名称和提示最适合的描述。如果你认为修改原始输入最终会得到更好的语言模型响应，你也可以修改原始输入。\n",
    "\n",
    "<< 格式化 >>\n",
    "返回一个markdown代码片段，其中包含一个格式化为如下样式的JSON对象：\n",
    "```json\n",
    "{{{{\n",
    "    \"destination\": string \\\\ 使用的提示名称或\"DEFAULT\"\n",
    "    \"next_inputs\": string \\\\ 可能修改过的原始输入\n",
    "}}}}\n",
    "```\n",
    "\n",
    "记住：\"destination\" 必须是下面指定的候选提示名称之一，或者如果输入不适合任何候选提示，它可以是\"DEFAULT\"。\n",
    "记住：\"next_inputs\" 可以是原始输入，如果你认为不需要任何修改。\n",
    "\n",
    "<< 候选提示 >>\n",
    "{destinations}\n",
    "\n",
    "<< 输入 >>\n",
    "{{input}}\n",
    "\n",
    "<< 输出 >>\n",
    "\"\"\"\n",
    "router_template = router_prompt_template.format(destinations=destinations_str)\n",
    "router_prompt = PromptTemplate(\n",
    "    template=router_template,\n",
    "    input_variables=[\"input\"],\n",
    "    output_parser=RouterOutputParser(),\n",
    ")\n",
    "router_chain = LLMRouterChain.from_llm(llm, router_prompt)\n",
    "\n",
    "# 构建RouterChains\n",
    "chain = MultiPromptChain(\n",
    "    router_chain=router_chain,\n",
    "    destination_chains=destination_chains,\n",
    "    default_chain=default_chain,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new MultiPromptChain chain...\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aihe/PycharmProjects/langchan_tutorial/venv/lib/python3.9/site-packages/langchain/chains/llm.py:275: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "物理: {'input': '什么是黑体辐射?'}\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "黑体辐射是指热物体，如火或太阳，发出的电磁波辐射。它的特征是温度越高，发出的电磁波越多，发出的频率也越高。\n"
     ]
    }
   ],
   "source": [
    "print(chain.run(\"什么是黑体辐射?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new MultiPromptChain chain...\u001B[0m\n",
      "数学: {'input': '计算 7 乘以 24 乘以 60 等于多少？'}\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "答案：7 乘以 24 乘以 60 等于 8,640。\n"
     ]
    }
   ],
   "source": [
    "print(chain.run(\"计算下7乘以24，然后再乘以60等于多少？\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new MultiPromptChain chain...\u001B[0m\n",
      "None: {'input': '什么是彩虹？'}\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      " 彩虹是一种美丽的天空现象，由多种颜色的光线混合而成。它由水滴和冰晶反射出来的多种颜色的光线组成，这些颜色从红色到紫色排列。\n"
     ]
    }
   ],
   "source": [
    "print(chain.run(\"什么是彩虹？\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
